{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request"
      ],
      "metadata": {
        "id": "EvoNG4Nem64J"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Implementing Edge Detection\n",
        "Write a Python function using OpenCV that takes an image file path as input, applies Canny edge detection on the image, and displays the original and edge-detected images side by side."
      ],
      "metadata": {
        "id": "jIjGPRJgJyKd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAMcnu2VIMqs"
      },
      "outputs": [],
      "source": [
        "def edge_detector(file_path):\n",
        "  img_1=cv.imread(file_path)\n",
        "  edge_detected_img_1=cv.Canny(img_1,100,200)\n",
        "  return cv2_imshow(img_1),cv2_imshow(edge_detected_img_1)\n",
        "\n",
        "path=input(\"Enter path of file: \")\n",
        "edge_detector(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Face and Eye Detection\n",
        "Create a function that detects faces and eyes in a given image using Haar cascades in OpenCV. The function should draw rectangles around detected faces and eyes and display the output image.\n",
        "\n"
      ],
      "metadata": {
        "id": "J0C3efhoJ87r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def face_eye_detector():\n",
        "  img=cv.imread('/content/face.jpg')\n",
        "  gray=cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "\n",
        "  url = 'https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_frontalface_default.xml'\n",
        "  urllib.request.urlretrieve(url, 'haarcascade_frontalface_default.xml')\n",
        "  eye_url = 'https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_eye.xml'\n",
        "  urllib.request.urlretrieve(eye_url, 'haarcascade_eye.xml')\n",
        "\n",
        "  face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "  eye_cascade=cv.CascadeClassifier('haarcascade_eye.xml')\n",
        "\n",
        "  faces=face_cascade.detectMultiScale(gray,1.3,5)\n",
        "  for (x,y,w,h) in faces:\n",
        "    face_img = cv.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "    roi_gray=face_img[y:y+h,x:x+w]\n",
        "    roi_color = face_img[y:y+h, x:x+w]\n",
        "\n",
        "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
        "    for (ex,ey,ew,eh) in eyes:\n",
        "      cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
        "  return cv2_imshow(face_img)\n",
        "\n",
        "face_eye_detector()\n"
      ],
      "metadata": {
        "id": "urLLzriDKE3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Image Cropping Based on Facial Features\n",
        "Write a function that takes an image path as input and detects faces. If exactly one face is detected, return the cropped image of the face. Use Haar cascades for face detection.\n",
        "\n"
      ],
      "metadata": {
        "id": "0LqmSAzjKFs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def facial_crop(file_path):\n",
        "  url = 'https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_frontalface_default.xml'\n",
        "  urllib.request.urlretrieve(url, 'haarcascade_frontalface_default.xml')\n",
        "  face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "  image_2=cv.imread(file_path)\n",
        "  gray_2=cv.cvtColor(image_2,cv.COLOR_BGR2GRAY)\n",
        "\n",
        "  faces = face_cascade.detectMultiScale(gray_2, 1.1, 3)\n",
        "  for (x,y,w,h) in faces:\n",
        "    face_img = cv.rectangle(image_2,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "    roi_color = face_img[y:y+h, x:x+w]\n",
        "\n",
        "  if len(faces)==1:\n",
        "    cropped_image = cv2_imshow(roi_color)\n",
        "    return cropped_image\n",
        "  else:\n",
        "    print(\"Multiple faces detected\")\n",
        "\n",
        "image2_path=input(\"Enter path of image: \")\n",
        "facial_crop(image2_path)\n"
      ],
      "metadata": {
        "id": "BegDgYKVKXzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Feature Matching with ORB\n",
        "Create a Python script that uses ORB to detect and match features between two images. The script should display the matched keypoints on the output image."
      ],
      "metadata": {
        "id": "QgyckcTYKd_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_img=cv.imread('/content/book in hand.png')\n",
        "train_img=cv.imread('/content/book in table.jpg')\n",
        "\n",
        "gray_query_img=cv.cvtColor(query_img,cv.COLOR_BGR2GRAY)\n",
        "gray_train_img=cv.cvtColor(train_img,cv.COLOR_BGR2GRAY)\n",
        "\n",
        "orb=cv.ORB_create()\n",
        "\n",
        "query_kp, query_ds = orb.detectAndCompute(gray_query_img,None)\n",
        "train_kp, train_ds = orb.detectAndCompute(gray_train_img,None)\n",
        "\n",
        "matcher = cv.BFMatcher()\n",
        "matches = matcher.match(query_ds,train_ds)\n",
        "matched_kp1 = [query_kp[m.queryIdx] for m in matches]\n",
        "matched_kp2 = [train_kp[m.trainIdx] for m in matches]\n",
        "\n",
        "image1_with_matched_kp = cv.drawKeypoints(query_img, matched_kp1, None, color=(0, 255, 0), flags=cv.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)\n",
        "image2_with_matched_kp = cv.drawKeypoints(train_img, matched_kp2, None, color=(0, 255, 0), flags=cv.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)\n",
        "\n",
        "cv2_imshow(image1_with_matched_kp)\n",
        "cv2_imshow(image2_with_matched_kp)\n",
        "\n"
      ],
      "metadata": {
        "id": "BcuGQ9prknoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Applying Gaussian Blur for Noise Reduction\n",
        "Write a function that applies a Gaussian blur to an image to reduce noise and displays both the original and blurred images.\n",
        "\n"
      ],
      "metadata": {
        "id": "lDA24x31KjZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def noise_reduction():\n",
        "  image_3=cv.imread('/content/mountains.jpg')\n",
        "  blur_image_3=cv.GaussianBlur(image_3,(7,7),cv.BORDER_DEFAULT)\n",
        "  return cv2_imshow(image_3),cv2_imshow(blur_image_3)\n",
        "\n",
        "noise_reduction()"
      ],
      "metadata": {
        "id": "_P-y1icCKpmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pyramid Transform for Image Scaling\n",
        "Create a function that creates a pyramid of images (both up and down) for a given image and displays the results."
      ],
      "metadata": {
        "id": "LL0N4o8PK226"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pyramid_transform():\n",
        "  image_7=cv.imread('/content/book in table.jpg')\n",
        "  image_7_copy=image_7.copy()\n",
        "  levels=int(input(\"Enter limit of levels for transformation: \"))\n",
        "  print(\"Gaussian Pyramid (Downscaling):\")\n",
        "  downscaled_images = [image_7_copy]\n",
        "  for i in range(levels):\n",
        "       image = cv.pyrDown(image_7_copy)\n",
        "       downscaled_images.append(image)\n",
        "       print(f\"Downscaled Level {i + 1}\")\n",
        "       cv2_imshow(image)\n",
        "\n",
        "  print(\"\\nGaussian Pyramid (Upscaling):\")\n",
        "  for i in range(levels, 0, -1):\n",
        "       upscaled_image = cv.pyrUp(downscaled_images[i])\n",
        "       print(f\"Upscaled Level {levels - i + 1}\")\n",
        "       cv2_imshow(upscaled_image)\n",
        "\n",
        "  print(\"Pyramid creation complete!\")\n",
        "pyramid_transform()"
      ],
      "metadata": {
        "id": "cUc3TOYHK7mS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Implement Harris Corner Detection in Python\n",
        "Write a Python function using OpenCV that takes an image file as input and applies the Harris Corner Detection algorithm. Your function should display the original image with the detected corners marked. Include parameters to specify the block size, ksize, and free parameter for flexibility."
      ],
      "metadata": {
        "id": "0d9yPfShK8cM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Harris_Corner_Detection(image_3):\n",
        "  gray_image_3=cv.cvtColor(image_3,cv.COLOR_BGR2GRAY)\n",
        "  detection=cv.cornerHarris(gray_image_3,blockSize=2,ksize=3,k=0.04)\n",
        "  detection=cv.dilate(detection,None)\n",
        "  image_3[detection > 0.01 * detection.max()] = [0, 255, 0]\n",
        "  return cv2_imshow(image_3)\n",
        "image_3_path=input(\"Enter the path of the image: \")\n",
        "image_3=cv.imread(image_3_path)\n",
        "Harris_Corner_Detection(image_3)\n"
      ],
      "metadata": {
        "id": "cl6JEWZuLCaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SIFT Keypoint Detection and Description\n",
        "Create a function that reads an image, converts it to grayscale, and then applies the SIFT algorithm to detect keypoints and compute descriptors. Ensure the detected keypoints are visualized on the original image."
      ],
      "metadata": {
        "id": "_kKG-zIuLECF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sift_detector():\n",
        "  image_4 = cv.imread('book in table.jpg')\n",
        "  gray_image_4 = cv.cvtColor(image_4, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "  sift = cv.xfeatures2d.SIFT_create()\n",
        "  kp, des = sift.detectAndCompute(gray_image_4, None)\n",
        "\n",
        "  kp_image = cv.drawKeypoints(image_4, kp, None, color=(0, 255, 0), flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "  cv2_imshow(kp_image)\n",
        "\n",
        "sift_detector()"
      ],
      "metadata": {
        "id": "WLt-G4IGLJZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Feature Matching using ORB\n",
        "Develop a Python script that matches features between two images using the ORB algorithm. The script should display the matched features between the two images with lines connecting corresponding keypoints."
      ],
      "metadata": {
        "id": "7KeEnochLKpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_image=cv.imread('/content/book in hand.png')\n",
        "train_image=cv.imread('/content/book in table.jpg')\n",
        "\n",
        "gray_query_image=cv.cvtColor(query_image,cv.COLOR_BGR2GRAY)\n",
        "gray_train_image=cv.cvtColor(train_image,cv.COLOR_BGR2GRAY)\n",
        "\n",
        "orb=cv.ORB_create()\n",
        "\n",
        "queryKeypoints, queryDescriptors = orb.detectAndCompute(gray_query_img,None)\n",
        "trainKeypoints, trainDescriptors = orb.detectAndCompute(gray_train_img,None)\n",
        "\n",
        "matcher = cv.BFMatcher()\n",
        "matches = matcher.match(queryDescriptors,trainDescriptors)\n",
        "\n",
        "output_image=cv.drawMatches(query_img,queryKeypoints,train_img,trainKeypoints,matches,None)\n",
        "cv2_imshow(output_image)\n",
        "\n"
      ],
      "metadata": {
        "id": "jTXyw4zmKi74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Implement FAST Corner Detection\n",
        "Write a Python function to implement the FAST corner detection algorithm. The function should accept an image and return the image with detected keypoints highlighted.\n",
        "\n"
      ],
      "metadata": {
        "id": "e9rbfBbrLR6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fast_corner():\n",
        "  image_5=cv.imread('/content/book in table.jpg')\n",
        "  gray_image=cv.cvtColor(image_5, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "  fast=cv.FastFeatureDetector_create()\n",
        "  fast.setNonmaxSuppression(False)\n",
        "\n",
        "  kp = fast.detect(gray_image, None)\n",
        "  kp_image = cv.drawKeypoints(image_5, kp, None, color=(0, 255, 0))\n",
        "\n",
        "  return cv2_imshow(kp_image)\n",
        "fast_corner()"
      ],
      "metadata": {
        "id": "FS3g035MLg2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Custom Canny Edge Detector Implementation\n",
        "Implement your own version of the Canny edge detection algorithm from scratch using Python (without using OpenCV functions). Your implementation should include:\n",
        "\n",
        "Gaussian filtering for noise reduction. Calculation of gradient magnitude and direction. Non-maximum suppression. Hysteresis thresholding. Your function should take an image as input and return an image with detected edges"
      ],
      "metadata": {
        "id": "U2Xa3Mf5LhoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_canny(image):\n",
        "  if len(image.shape) == 3:\n",
        "    image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "  kernel_size = 3\n",
        "   #Gussian filtering\n",
        "  filtered_image = np.zeros_like(image)\n",
        "  for i in range(image.shape[0]):\n",
        "    for j in range(image.shape[1]):\n",
        "      neighborhood = image[i:i + kernel_size, j:j + kernel_size]\n",
        "      filtered_image[i, j] = np.mean(neighborhood)\n",
        "\n",
        "    #Gradient magnitude and direction\n",
        "  sobel_y = cv.Sobel(filtered_image, cv.CV_64F, 0, 1, ksize=3)\n",
        "  sobel_x = cv.Sobel(filtered_image, cv.CV_64F, 1, 0, ksize=3)\n",
        "\n",
        "  gradient_magnitude = np.sqrt(sobel_x ** 2 + sobel_y ** 2)\n",
        "  gradient_magnitude = np.uint8(gradient_magnitude / np.max(gradient_magnitude) * 255)\n",
        "  gradient_direction = np.arctan2(sobel_y, sobel_x) * 180 / np.pi\n",
        "\n",
        "    # Non-maximum suppression\n",
        "  rows, cols = gradient_magnitude.shape\n",
        "  nms_result = np.zeros((rows, cols), dtype=np.uint8)\n",
        "\n",
        "  for i in range(1, rows - 1):\n",
        "    for j in range(1, cols - 1):\n",
        "      angle = gradient_direction[i, j]\n",
        "      if (0 <= angle < 22.5) or (157.5 <= angle < 180):\n",
        "        neighbors = [gradient_magnitude[i, j - 1], gradient_magnitude[i, j + 1]]\n",
        "      elif (22.5 <= angle < 67.5):\n",
        "        neighbors = [gradient_magnitude[i - 1, j + 1], gradient_magnitude[i + 1, j - 1]]\n",
        "      elif (67.5 <= angle < 112.5):\n",
        "        neighbors = [gradient_magnitude[i - 1, j], gradient_magnitude[i + 1, j]]\n",
        "      else:\n",
        "        neighbors = [gradient_magnitude[i - 1, j - 1], gradient_magnitude[i + 1, j + 1]]\n",
        "\n",
        "      if gradient_magnitude[i, j] >= neighbors[0] and gradient_magnitude[i, j] >= neighbors[1]:\n",
        "        nms_result[i, j] = gradient_magnitude[i, j]\n",
        "      else:\n",
        "        nms_result[i, j] = 0\n",
        "\n",
        "    # Hysteresis thresholding\n",
        "  final_result = np.zeros_like(image, dtype=np.uint8)\n",
        "  strong_edges = (nms_result > 100)\n",
        "  weak_edges = (nms_result >= 50) & (nms_result <= 100)\n",
        "\n",
        "  for i in range(1, rows - 1):\n",
        "    for j in range(1, cols - 1):\n",
        "      if weak_edges[i, j]:\n",
        "        if np.any(strong_edges[i-1:i+2, j-1:j+2]):\n",
        "          final_result[i, j] = 255\n",
        "        else:\n",
        "          final_result[i, j] = 0\n",
        "  final_result[strong_edges] = 255\n",
        "  return cv2_imshow( final_result)\n",
        "\n",
        "image_8 = cv.imread('/content/book in table.jpg')\n",
        "custom_canny(image_8)\n"
      ],
      "metadata": {
        "id": "wov5Rp7-YSS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Multi-Scale Feature Detection\n",
        "Create a function that applies multi-scale feature detection using the Laplacian of Gaussian (LoG) method. This function should take an image and a list of sigma values as input, and return an image or set of images showing detected features at the different scales.\n",
        "\n"
      ],
      "metadata": {
        "id": "xIUQ7tZHLmgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def laplacian_of_gaussian(image,sigma_list):\n",
        "  combined_image = np.zeros_like(image, dtype=np.float32)\n",
        "  for i in range(0,len(sigma_list)):\n",
        "    blur_image=cv.GaussianBlur(image,(0,0),sigma_list[i])\n",
        "    print(\"image no. \",i+1)\n",
        "    gray_image=cv.cvtColor(blur_image,cv.COLOR_BGR2GRAY)\n",
        "    dst=cv.Laplacian(gray_image,cv.CV_64F)\n",
        "    abs_laplacian = np.abs(dst)\n",
        "    cv2_imshow(abs_laplacian)\n",
        "\n",
        "\n",
        "image_path=input(\"Enter the path of image: \")\n",
        "image_6=cv.imread(image_path)\n",
        "sigma_values=[0.05,0.1,0.2,0.3,0.4,0.5]\n",
        "laplacian_of_gaussian(image_6,sigma_values)"
      ],
      "metadata": {
        "id": "i7_0PN4ALtxS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}