{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93XQHTufB3_O"
      },
      "source": [
        "### Implement Edge Detection\n",
        "\n",
        "Write a Python function using OpenCV that takes an image file path as input, applies Canny edge detection on the image, and displays the original and edge-detected images side by side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVSmMDmk_s1R"
      },
      "outputs": [],
      "source": [
        "# Write Your code here.\n",
        "import cv2 as cv \n",
        "img=cv.imread(r\"C:\\Users\\Ritika Batra\\OneDrive\\Desktop\\my files\\zoomed.jpg\")\n",
        "canny=cv.Canny(img,200,200)\n",
        "cv.imshow(\"Original\",img)\n",
        "cv.imshow(\"Edgy\",canny)\n",
        "cv.waitKey(0)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRzoOxEvCPyl"
      },
      "source": [
        "### Face and Eye Detection\n",
        "\n",
        "Create a function that detects faces and eyes in a given image using Haar cascades in OpenCV. The function should draw rectangles around detected faces and eyes and display the output image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4irktxYCQKJ"
      },
      "outputs": [],
      "source": [
        "# Write Your code here.\n",
        "import cv2\n",
        "img = cv2.imread(r\"C:\\Users\\Ritika Batra\\OneDrive\\Desktop\\my files\\zoomed.jpg\")\n",
        "\n",
        "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "facecascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "eyecascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
        "\n",
        "faces = facecascade.detectMultiScale(gray, 1.3, 4)\n",
        "print('Number of detected faces:', len(faces))\n",
        "\n",
        "for (x,y,w,h) in faces:\n",
        "   roi_gray = gray[y:y+h, x:x+w]\n",
        "   roi_color = img[y:y+h, x:x+w]\n",
        "   \n",
        "   eyes = eyecascade.detectMultiScale(roi_gray)\n",
        "\n",
        "   face_rect = facecascade.detectMultiScale(img,scaleFactor=1.2,minNeighbors=5)\n",
        "\n",
        "   for (x,y,w,h) in face_rect:\n",
        "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
        "   \n",
        "   \n",
        "   for (ex,ey,ew,eh) in eyes:\n",
        "      cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
        "\n",
        "cv2.imshow('Eyes Detection',img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h59b-BnvCbWe"
      },
      "source": [
        "###Image Cropping Based on Facial Features\n",
        "\n",
        "Write a function that takes an image path as input and detects faces. If exactly one face is detected, return the cropped image of the face. Use Haar cascades for face detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sukHNd-sCbHe"
      },
      "outputs": [],
      "source": [
        "# Write Your code here.\n",
        "import cv2\n",
        "img = cv2.imread(r\"C:\\Users\\Ritika Batra\\OneDrive\\Desktop\\my files\\zoomed.jpg\")\n",
        "\n",
        "\n",
        "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "facecascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "eyecascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
        "\n",
        "\n",
        "faces = facecascade.detectMultiScale(gray, 1.3, 4)\n",
        "  \n",
        "if len(faces) ==1 :\n",
        "    for (x,y,w,h) in faces:\n",
        "        roi_color = img[y:y+h, x:x+w]\n",
        "        face_rect = facecascade.detectMultiScale(img,scaleFactor=1.2,minNeighbors=5)\n",
        "\n",
        "        for (x,y,w,h) in face_rect:\n",
        "          cropped=img[y:y+h, x:x+w]\n",
        "\n",
        "          cv2.imshow(\"Cropped face\",cropped)\n",
        "          cv2.waitKey(0) \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zeYFj9nCnqX"
      },
      "source": [
        "### Feature Matching with ORB\n",
        "Create a Python script that uses ORB to detect and match features between two images. The script should display the matched keypoints on the output image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpczpHxCCr74"
      },
      "outputs": [],
      "source": [
        "# Write Your code here.\n",
        "import numpy as np\n",
        "import cv2\n",
        " \n",
        "queryimg = cv2.imread(r\"C:\\Users\\Ritika Batra\\OneDrive\\Desktop\\my files\\science.jpg\")\n",
        "trainimg = cv2.imread(r\"C:\\Users\\Ritika Batra\\OneDrive\\Desktop\\my files\\train.jpg\")\n",
        " \n",
        "query_img_bw = cv2.cvtColor(queryimg,cv2.COLOR_BGR2GRAY)\n",
        "train_img_bw = cv2.cvtColor(trainimg, cv2.COLOR_BGR2GRAY)\n",
        " \n",
        "orb = cv2.ORB_create()\n",
        "\n",
        "queryKeypoints, queryDescriptors = orb.detectAndCompute(query_img_bw,None)\n",
        "trainKeypoints, trainDescriptors = orb.detectAndCompute(train_img_bw,None)\n",
        "\n",
        "matcher = cv2.BFMatcher()\n",
        "matches = matcher.match(queryDescriptors,trainDescriptors)\n",
        "\n",
        "final_img = cv2.drawMatches(queryimg, queryKeypoints, trainimg, trainKeypoints, matches[:20],None)\n",
        " \n",
        "final_img = cv2.resize(final_img, (1000,650))\n",
        "\n",
        "cv2.imshow(\"Matches\", final_img)\n",
        "cv2.waitKey(0)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sUEn0RXCsiB"
      },
      "source": [
        "### Applying Gaussian Blur for Noise Reduction\n",
        "Write a function that applies a Gaussian blur to an image to reduce noise and displays both the original and blurred images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_lKp3bICzdl"
      },
      "outputs": [],
      "source": [
        "# Write Your code here.\n",
        "import cv2 as cv\n",
        "\n",
        "img=cv.imread(r\"C:\\Users\\Ritika Batra\\OneDrive\\Desktop\\my files\\zoomed.jpg\")\n",
        "blur=cv.GaussianBlur(img,(11,11),0)\n",
        "cv.imshow(\"blurff\",blur)\n",
        "cv.imshow(\"original\",img)\n",
        "cv.waitKey(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fidnIKLWCzCx"
      },
      "source": [
        "### Pyramid Transform for Image Scaling\n",
        "Create a function that creates a pyramid of images (both up and down) for a given image and displays the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABndA3roC5fV"
      },
      "outputs": [],
      "source": [
        "# Write Your code here.\n",
        "\n",
        "\n",
        "\n",
        "import cv2 \n",
        "import matplotlib.pyplot as plt \n",
        "  \n",
        "img = cv2.imread(r\"C:\\Users\\Ritika Batra\\OneDrive\\Desktop\\my files\\zoomed.jpg\") \n",
        "  \n",
        "layer = img.copy() \n",
        "  \n",
        "for i in range(4): \n",
        "    plt.subplot(2, 2, i + 1) \n",
        "  \n",
        "    layer1 = cv2.pyrDown(layer) \n",
        "    layer2 = cv2.pyrUp(layer)\n",
        "  \n",
        "    plt.imshow(layer1) \n",
        "    cv2.imshow(f\"str{i}\", layer1)\n",
        "    plt.imshow(layer2) \n",
        "    cv2.imshow(f\"str{i}\", layer2)  \n",
        "    cv2.waitKey(0) \n",
        "      \n",
        "  \n",
        "cv2.destroyAllWindows() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHlKUjccC5La"
      },
      "source": [
        "### Implement Harris Corner Detection in Python\n",
        "Write a Python function using OpenCV that takes an image file as input and applies the Harris Corner Detection algorithm. Your function should display the original image with the detected corners marked. Include parameters to specify the block size, ksize, and free parameter for flexibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beKkD_y0C7Ke"
      },
      "outputs": [],
      "source": [
        "# Write Your code here.\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        " \n",
        "\n",
        "img = cv.imread(r\"C:\\Users\\Ritika Batra\\OneDrive\\Desktop\\my files\\zoomed.jpg\")\n",
        "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        " \n",
        "gray = np.float32(gray)\n",
        "ds = cv.cornerHarris(gray,2,3,0.04)\n",
        " \n",
        "ds = cv.dilate(ds,None)\n",
        " \n",
        "img[ds>0.01*ds.max()]=[0,255,0] \n",
        " \n",
        "cv.imshow('ds',img)\n",
        "if cv.waitKey(0) & 0xff == 27:\n",
        "    cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46_GNSP5DE-Q"
      },
      "source": [
        "### SIFT Keypoint Detection and Description\n",
        "Create a function that reads an image, converts it to grayscale, and then applies the SIFT algorithm to detect keypoints and compute descriptors. Ensure the detected keypoints are visualized on the original image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNml8psQDJcb"
      },
      "outputs": [],
      "source": [
        "# Write Your code here.\n",
        "import cv2\n",
        " \n",
        "img = cv2.imread(r\"C:\\Users\\Ritika Batra\\OneDrive\\Desktop\\my files\\zoomed.jpg\")\n",
        " \n",
        "\n",
        "gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        " \n",
        "sift = cv2.SIFT_create()\n",
        "key = sift.detect(gray, None)\n",
        " \n",
        "\n",
        "img=cv2.drawKeypoints(gray ,key ,img ,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        " \n",
        "cv2.imshow('image-with-keypoints.jpg', img)\n",
        "cv2.waitKey(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9Aa7newDJxY"
      },
      "source": [
        "### Feature Matching using ORB\n",
        "Develop a Python script that matches features between two images using the ORB algorithm. The script should display the matched features between the two images with lines connecting corresponding keypoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSFtPxbWDRFz"
      },
      "outputs": [],
      "source": [
        "# Write Your code here.\n",
        "# Write Your code here.\n",
        "import numpy as np\n",
        "import cv2\n",
        " \n",
        "queryimg = cv2.imread(r\"C:\\Users\\Ritika Batra\\OneDrive\\Desktop\\my files\\science.jpg\")\n",
        "trainimg = cv2.imread(r\"C:\\Users\\Ritika Batra\\OneDrive\\Desktop\\my files\\train.jpg\")\n",
        " \n",
        "\n",
        "query_img_bw = cv2.cvtColor(queryimg,cv2.COLOR_BGR2GRAY)\n",
        "train_img_bw = cv2.cvtColor(trainimg, cv2.COLOR_BGR2GRAY)\n",
        " \n",
        "orb = cv2.ORB_create()\n",
        "  \n",
        "queryKeypoints, queryDescriptors = orb.detectAndCompute(query_img_bw,None)\n",
        "trainKeypoints, trainDescriptors = orb.detectAndCompute(train_img_bw,None)\n",
        "\n",
        "matcher = cv2.BFMatcher()\n",
        "matches = matcher.match(queryDescriptors,trainDescriptors)\n",
        " \n",
        "final_img = cv2.drawMatches(queryimg, queryKeypoints, trainimg, trainKeypoints, matches[:20],None)\n",
        " \n",
        "final_img = cv2.resize(final_img, (1000,650))\n",
        "\n",
        "cv2.imshow(\"Matches\", final_img)\n",
        "cv2.waitKey(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyuM-UuYDRbA"
      },
      "source": [
        "### Implement FAST Corner Detection\n",
        "Write a Python function to implement the FAST corner detection algorithm. The function should accept an image and return the image with detected keypoints highlighted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HgLq8f_DTnO"
      },
      "outputs": [],
      "source": [
        "# Write Your code here.\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "def myfun(path):\n",
        " img = cv.imread(path, cv.IMREAD_GRAYSCALE) \n",
        " \n",
        " fast = cv.FastFeatureDetector_create()\n",
        "\n",
        " kp = fast.detect(img,None)\n",
        " img2 = cv.drawKeypoints(img, kp, None, color=(255,0,0))\n",
        " return img2\n",
        "\n",
        "path=r\"C:\\Users\\Ritika Batra\\OneDrive\\Desktop\\my files\\zoomed.jpg\"\n",
        "myfun(path) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOJ-25wrDpiC"
      },
      "source": [
        "Tough questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tovusHoWDT6G"
      },
      "source": [
        "### Custom Canny Edge Detector Implementation\n",
        "Implement your own version of the Canny edge detection algorithm from scratch using Python (without using OpenCV functions). Your implementation should include:\n",
        "\n",
        "Gaussian filtering for noise reduction.\n",
        "Calculation of gradient magnitude and direction.\n",
        "Non-maximum suppression.\n",
        "Hysteresis thresholding. Your function should take an image as input and return an image with detected edges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICcFqoUyDr_b"
      },
      "outputs": [],
      "source": [
        "# Write Your code here.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIkqyboUDsWO"
      },
      "source": [
        "### Multi-Scale Feature Detection\n",
        "Create a function that applies multi-scale feature detection using the Laplacian of Gaussian (LoG) method. This function should take an image and a list of sigma values as input, and return an image or set of images showing detected features at the different scales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZ3prYBsDwPy"
      },
      "outputs": [],
      "source": [
        "# Write Your code here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCpFBjRSD8yh"
      },
      "source": [
        "## Bonus Question\n",
        "\n",
        "Do your Research on how can we make a 3d model from the Refined frames.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVr5vt5FEQSr"
      },
      "outputs": [],
      "source": [
        "### Write your answer here."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
