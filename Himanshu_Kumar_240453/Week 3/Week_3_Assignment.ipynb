{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93XQHTufB3_O"
      },
      "source": [
        "### Implement Edge Detection\n",
        "\n",
        "Write a Python function using OpenCV that takes an image file path as input, applies Canny edge detection on the image, and displays the original and edge-detected images side by side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVSmMDmk_s1R"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "img=cv.imread(\"image.jpg\")\n",
        "canny=cv.Canny(img,150,215)\n",
        "canny_bgr=cv.cvtColor(canny,cv.COLOR_GRAY2BGR)\n",
        "canny=cv.resize(canny_bgr,(img.shape[1],img.shape[0]))\n",
        "combine=cv.hconcat([img,canny])\n",
        "cv.imshow(\"Original and Edge Detected\",combine)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRzoOxEvCPyl"
      },
      "source": [
        "### Face and Eye Detection\n",
        "\n",
        "Create a function that detects faces and eyes in a given image using Haar cascades in OpenCV. The function should draw rectangles around detected faces and eyes and display the output image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4irktxYCQKJ"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "img=cv.imread(\"image.jpg\")\n",
        "gray=cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "face_cascade=cv.CascadeClassifier(cv.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "eye_cascade=cv.CascadeClassifier(cv.data.haarcascades + \"haarcascade_eye.xml\")\n",
        "faces=face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "for (x,y,w,h) in faces:\n",
        "    cv.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) #blue rectangles for faces\n",
        "    #region of interest (roi)\n",
        "    roi_gray=gray[y:y+h,x:x+w]\n",
        "    roi_color=img[y:y+h,x:x+w]\n",
        "    eyes=eye_cascade.detectMultiScale(roi_gray,1.1,5,10,(15,15))\n",
        "    for (ex,ey,ew,eh) in eyes:\n",
        "        cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2) #green rectangles for eyes\n",
        "cv.imshow('Eyes Detected',img)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h59b-BnvCbWe"
      },
      "source": [
        "### Image Cropping Based on Facial Features\n",
        "\n",
        "Write a function that takes an image path as input and detects faces. If exactly one face is detected, return the cropped image of the face. Use Haar cascades for face detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sukHNd-sCbHe"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "def face_detect(path):\n",
        "    img=cv.imread(path)\n",
        "    gray=cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "    face_cascade=cv.CascadeClassifier(cv.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "    faces=face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "    num_faces=len(faces)\n",
        "    if num_faces==1:\n",
        "        for (x,y,w,h) in faces:\n",
        "            img_crop=img[y:y+h,x:x+w]\n",
        "            break\n",
        "        cv.imshow(\"Single Face\",img_crop)\n",
        "    else:\n",
        "        for (x,y,w,h) in faces:\n",
        "            cv.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
        "        cv.imshow(\"Multiple Faces Detected\",img)\n",
        "    cv.waitKey(0)\n",
        "    cv.destroyAllWindows()\n",
        "face_detect(\"singleface.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zeYFj9nCnqX"
      },
      "source": [
        "### Feature Matching with ORB\n",
        "Create a Python script that uses ORB to detect and match features between two images. The script should display the matched keypoints on the output image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpczpHxCCr74"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "img1=cv.imread(\"./Week 3/image1.jpg\")\n",
        "img2=cv.imread(\"./Week 3/image2.jpg\")\n",
        "gray1=cv.cvtColor(img1,cv.COLOR_BGR2GRAY)\n",
        "gray2=cv.cvtColor(img2,cv.COLOR_BGR2GRAY)\n",
        "orb=cv.ORB_create()\n",
        "kp1,des1=orb.detectAndCompute(gray1,None)\n",
        "kp2,des2=orb.detectAndCompute(gray2,None)\n",
        "#brute force matcher\n",
        "bf=cv.BFMatcher(cv.NORM_HAMMING,crossCheck=True)\n",
        "matches=bf.match(des1,des2)\n",
        "matches=sorted(matches,key=lambda x:x.distance)\n",
        "img_matches=cv.drawMatches(img1,kp1,img2,kp2,matches[:10],None,cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
        "cv.imshow(\"ORB Matches\",img_matches)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sUEn0RXCsiB"
      },
      "source": [
        "### Applying Gaussian Blur for Noise Reduction\n",
        "Write a function that applies a Gaussian blur to an image to reduce noise and displays both the original and blurred images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_lKp3bICzdl"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "def blur_img(path):\n",
        "    img=cv.imread(path)\n",
        "    blur=cv.GaussianBlur(img,(5,5),5)\n",
        "    cv.imshow(\"Original\",img)\n",
        "    cv.imshow(\"Blurred\",blur)\n",
        "    cv.waitKey(0)\n",
        "    cv.destroyAllWindows()\n",
        "blur_img(\"multiface.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fidnIKLWCzCx"
      },
      "source": [
        "### Pyramid Transform for Image Scaling\n",
        "Create a function that creates a pyramid of images (both up and down) for a given image and displays the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABndA3roC5fV"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "def pyramid(path):\n",
        "    img=cv.imread(path)\n",
        "    cv.imshow(\"Original\",img)\n",
        "    for i in range(5):\n",
        "        lr=cv.pyrDown(img)\n",
        "        cv.imshow(\"Down Pyramid\"+f\" {i+1}\",lr)\n",
        "        img=lr\n",
        "    img=cv.imread(path)\n",
        "    for i in range(5):\n",
        "        lr=cv.pyrUp(img)\n",
        "        cv.imshow(\"Up Pyramid\"+f\" {i+1}\",lr)\n",
        "        img=lr\n",
        "    cv.waitKey(0)\n",
        "    cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHlKUjccC5La"
      },
      "source": [
        "### Implement Harris Corner Detection in Python\n",
        "Write a Python function using OpenCV that takes an image file as input and applies the Harris Corner Detection algorithm. Your function should display the original image with the detected corners marked. Include parameters to specify the block size, ksize, and free parameter for flexibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beKkD_y0C7Ke"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "def harris_corner(path,blocksize=2,ksize=3,k=0.04):\n",
        "    img=cv.imread(path)\n",
        "    gray=cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "    gray=np.float32(gray)\n",
        "    corners=cv.cornerHarris(gray,blocksize,ksize,k)\n",
        "    corners=cv.dilate(corners,None)\n",
        "    threshold=0.01*corners.max()\n",
        "    img[corners>threshold]=[0,0,225]\n",
        "    cv.imshow(\"Harris Corners Detected\",img)\n",
        "    cv.waitKey(0)\n",
        "    cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46_GNSP5DE-Q"
      },
      "source": [
        "### SIFT Keypoint Detection and Description\n",
        "Create a function that reads an image, converts it to grayscale, and then applies the SIFT algorithm to detect keypoints and compute descriptors. Ensure the detected keypoints are visualized on the original image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNml8psQDJcb"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "def sift(path):\n",
        "    img=cv.imread(path)\n",
        "    gray=cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "    sift=cv.SIFT_create()\n",
        "    kp,des=sift.detectAndCompute(gray,None)\n",
        "    kp_img=cv.drawKeypoints(img,kp,None,cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "    cv.imshow(\"SIFT Detected\",kp_img)\n",
        "    cv.waitKey(0)\n",
        "    cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9Aa7newDJxY"
      },
      "source": [
        "### Feature Matching using ORB\n",
        "Develop a Python script that matches features between two images using the ORB algorithm. The script should display the matched features between the two images with lines connecting corresponding keypoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSFtPxbWDRFz"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "img1=cv.imread(\"./Week 3/image1.jpg\")\n",
        "img2=cv.imread(\"./Week 3/image2.jpg\")\n",
        "gray1=cv.cvtColor(img1,cv.COLOR_BGR2GRAY)\n",
        "gray2=cv.cvtColor(img2,cv.COLOR_BGR2GRAY)\n",
        "orb=cv.ORB_create()\n",
        "kp1,des1=orb.detectAndCompute(gray1,None)\n",
        "kp2,des2=orb.detectAndCompute(gray2,None)\n",
        "#brute force matcher\n",
        "bf=cv.BFMatcher(cv.NORM_HAMMING,crossCheck=True)\n",
        "matches=bf.match(des1,des2)\n",
        "matches=sorted(matches,key=lambda x:x.distance)\n",
        "img_matches=cv.drawMatches(img1,kp1,img2,kp2,matches[:10],None,cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
        "cv.imshow(\"ORB Matches\",img_matches)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyuM-UuYDRbA"
      },
      "source": [
        "### Implement FAST Corner Detection\n",
        "Write a Python function to implement the FAST corner detection algorithm. The function should accept an image and return the image with detected keypoints highlighted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HgLq8f_DTnO"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "def fast_corner(path):\n",
        "    img=cv.imread(path)\n",
        "    gray=cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "    fast=cv.FastFeatureDetector_create()\n",
        "    fast.setThreshold(20)\n",
        "    fast.setNonmaxSuppression(True)\n",
        "    fast.setType(cv.FAST_FEATURE_DETECTOR_TYPE_9_16)\n",
        "    keypoints=fast.detect(gray,None)\n",
        "    kp_img=cv.drawKeypoints(img,keypoints,None,(255,0,0))\n",
        "    cv.imshow(\"FAST Corners Detected\",kp_img)\n",
        "    cv.waitKey(0)\n",
        "    cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOJ-25wrDpiC"
      },
      "source": [
        "Tough questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tovusHoWDT6G"
      },
      "source": [
        "### Custom Canny Edge Detector Implementation\n",
        "Implement your own version of the Canny edge detection algorithm from scratch using Python (without using OpenCV functions). Your implementation should include:\n",
        "\n",
        "Gaussian filtering for noise reduction.\n",
        "Calculation of gradient magnitude and direction.\n",
        "Non-maximum suppression.\n",
        "Hysteresis thresholding. Your function should take an image as input and return an image with detected edges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICcFqoUyDr_b"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "def custom_canny(path):\n",
        "    img=cv.imread(path)\n",
        "    blur=cv.GaussianBlur(img,(3,3),5) #noise reduction\n",
        "    gray=cv.cvtColor(blur,cv.COLOR_BGR2GRAY)\n",
        "    gx=cv.Sobel(gray,cv.CV_64F,1,0,ksize=3) #x direction of gradient\n",
        "    gy=cv.Sobel(gray,cv.CV_64F,0,1,ksize=3) #y direction of gradient\n",
        "    grad_mag=cv.magnitude(gx,gy) #gradient magnitude\n",
        "    grad_dir=cv.phase(gx,gy,angleInDegrees=True) #gradient direction\n",
        "\n",
        "    quant_dir=((grad_dir/45).astype(int)%4) #quantized direction\n",
        "    nms=np.zeros_like(grad_mag,dtype=np.float32) #non maximum suppression\n",
        "\n",
        "    rows,cols=grad_mag.shape\n",
        "\n",
        "    for i in range(1,rows-1):\n",
        "        for j in range(1,cols-1):\n",
        "            cur_dir=quant_dir[i,j] #current direction\n",
        "\n",
        "            if cur_dir==0: #0 degrees \n",
        "                neighbors=(grad_mag[i,j-1],grad_mag[i,j+1])\n",
        "            elif cur_dir==1: #45 degrees\n",
        "                neighbors=(grad_mag[i-1,j+1],grad_mag[i+1,j-1])\n",
        "            elif cur_dir==2: #90 degrees\n",
        "                neighbors=(grad_mag[i-1,j],grad_mag[i+1,j])\n",
        "            elif cur_dir==3: #135 degrees\n",
        "                neighbors=(grad_mag[i-1,j-1],grad_mag[i+1,j+1])\n",
        "            \n",
        "            if grad_mag[i,j]>=max(neighbors): #suppressing non max values\n",
        "                nms[i,j]=grad_mag[i,j]\n",
        "    \n",
        "    #hysteresis thresholding\n",
        "    nms=np.zeros_like(grad_mag,dtype=np.float32)\n",
        "\n",
        "    strong=255 #strong hysteresis\n",
        "    weak=75 #weak hysteresis\n",
        "\n",
        "    strong_pixels=(grad_mag>=100)\n",
        "    weak_pixels=(grad_mag>=50) & (grad_mag<100)\n",
        "\n",
        "    nms[strong_pixels]=strong\n",
        "    nms[weak_pixels]=weak\n",
        "\n",
        "    for i in range(1,rows-1):\n",
        "        for j in range(1,cols-1):\n",
        "            if nms[i,j]==weak: #if the pixel is weak\n",
        "                if any(nms[i + di, j + dj] == strong for di in [-1, 0, 1] for dj in [-1, 0, 1] if not (di == 0 and dj == 0)): #check 8 connectivity\n",
        "                    nms[i,j]=strong\n",
        "                else:\n",
        "                    nms[i,j]=0 #suppress the weak\n",
        "\n",
        "    nms_normalised=cv.normalize(nms,None,0,255,cv.NORM_MINMAX)\n",
        "    nms_normalised=nms_normalised.astype(np.uint8)\n",
        "\n",
        "    cv.imshow(\"Edge Detection\",nms_normalised)\n",
        "\n",
        "    cv.waitKey(0)\n",
        "    cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIkqyboUDsWO"
      },
      "source": [
        "### Multi-Scale Feature Detection\n",
        "Create a function that applies multi-scale feature detection using the Laplacian of Gaussian (LoG) method. This function should take an image and a list of sigma values as input, and return an image or set of images showing detected features at the different scales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZ3prYBsDwPy"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "def multiscale_feature(path,sigma=[]):\n",
        "    img=cv.imread(path)\n",
        "    gray=cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "    for i in sigma:\n",
        "        blur=cv.GaussianBlur(gray,(3,3),i)\n",
        "        laplacian=cv.Laplacian(blur,cv.CV_64F,(3,3))\n",
        "        log=cv.convertScaleAbs(laplacian)\n",
        "        cv.imshow(f\"Scale {i} Feature Detection\",log)\n",
        "    cv.waitKey(0)\n",
        "    cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCpFBjRSD8yh"
      },
      "source": [
        "## Bonus Question\n",
        "\n",
        "Do your Research on how can we make a 3d model from the Refined frames.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVr5vt5FEQSr"
      },
      "outputs": [],
      "source": [
        "#To create a 3D model from refined frames in OpenCV, we can start by capturing frames of the object or scene from different angles, ensuring good lighting and minimal blur. Then we can preprocess these frames by resizing, reducing noise, and enhancing edges. Then detect features using algorithms like SIFT or ORB, then match these features across frames to establish correspondences. Then we can use techniques like Structure-from-Motion (SfM) to compute camera poses and reconstruct sparse 3D points, followed by dense reconstruction using stereo matching or tools like COLMAP. Finally, convert the point cloud into a 3D mesh with libraries like Open3D, and optionally apply textures for a realistic model. OpenCV is key for preprocessing and feature extraction, while external libraries often handle advanced 3D reconstruction and visualization. This is all my research says and it will require lots of processing that we've learned so far."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
