{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93XQHTufB3_O"
      },
      "source": [
        "### Implement Edge Detection\n",
        "\n",
        "Write a Python function using OpenCV that takes an image file path as input, applies Canny edge detection on the image, and displays the original and edge-detected images side by side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "lVSmMDmk_s1R"
      },
      "outputs": [],
      "source": [
        "def canny(path):\n",
        "    image = cv.imread(path)\n",
        "    canny = cv.Canny(image,125,175)\n",
        "    canny = cv.cvtColor(canny,cv.COLOR_GRAY2BGR)\n",
        "\n",
        "    display_image = np.hstack((image,canny))\n",
        "\n",
        "    plt.imshow(display_image[:,:,::-1])\n",
        "    plt.axis(False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRzoOxEvCPyl"
      },
      "source": [
        "### Face and Eye Detection\n",
        "\n",
        "Create a function that detects faces and eyes in a given image using Haar cascades in OpenCV. The function should draw rectangles around detected faces and eyes and display the output image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "e4irktxYCQKJ"
      },
      "outputs": [],
      "source": [
        "def face_d_eye(image):\n",
        "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "    face_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    eye_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_eye.xml')\n",
        "\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.001, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    for (x,y,w,h) in faces:\n",
        "        face_img = cv.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "        roi_gray = gray[y:y+h, x:x+w]\n",
        "        roi_color = face_img[y:y+h, x:x+w]\n",
        "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
        "        for (ex,ey,ew,eh) in eyes:\n",
        "            cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
        "\n",
        "    face_img = cv.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "    plt.imshow(face_img[:,:,::-1])\n",
        "    plt.axis(False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h59b-BnvCbWe"
      },
      "source": [
        "###Image Cropping Based on Facial Features\n",
        "\n",
        "Write a function that takes an image path as input and detects faces. If exactly one face is detected, return the cropped image of the face. Use Haar cascades for face detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "sukHNd-sCbHe"
      },
      "outputs": [],
      "source": [
        "def face_d_eye(image):\n",
        "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "    face_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    \n",
        "\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.001, minNeighbors=5, minSize=(30, 30))\n",
        "    if len(faces)==1:\n",
        "        x,y,w,h = faces[0]\n",
        "\n",
        "    roi_color = image[y:y+h, x:x+w]\n",
        "    plt.imshow(roi_color[:,:,::-1])\n",
        "    plt.axis(False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zeYFj9nCnqX"
      },
      "source": [
        "### Feature Matching with ORB\n",
        "Create a Python script that uses ORB to detect and match features between two images. The script should display the matched keypoints on the output image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "qpczpHxCCr74"
      },
      "outputs": [],
      "source": [
        "def fetComp(path1,path2):\n",
        "    image1 = cv.imread(path1, cv.IMREAD_GRAYSCALE)\n",
        "    image2 = cv.imread(path2, cv.IMREAD_GRAYSCALE)\n",
        "\n",
        "    orb = cv.ORB_create()\n",
        "\n",
        "    keypoints1, descriptors1 = orb.detectAndCompute(image1, None)\n",
        "    keypoints2, descriptors2 = orb.detectAndCompute(image2, None)\n",
        "    \n",
        "    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
        "\n",
        "    matches = bf.match(descriptors1, descriptors2)\n",
        "\n",
        "    matches = sorted(matches, key=lambda x: x.distance)\n",
        "\n",
        "    image1_with_points = cv.cvtColor(image1, cv.COLOR_GRAY2BGR)\n",
        "    image2_with_points = cv.cvtColor(image2, cv.COLOR_GRAY2BGR)\n",
        "\n",
        "\n",
        "\n",
        "    for match in matches[:20]:\n",
        "        \n",
        "        pt1 = tuple(map(int, keypoints1[match.queryIdx].pt))\n",
        "        pt2 = tuple(map(int, keypoints2[match.trainIdx].pt))\n",
        "\n",
        "        a,b,c= np.random.rand(1,3)[0]*255\n",
        "        a=int(a)\n",
        "        b=int(b)\n",
        "        c=int(c)\n",
        "        \n",
        "        cv.circle(image1_with_points, pt1, radius=7, color=(a,b,c), thickness=-1)\n",
        "        cv.circle(image2_with_points, pt2, radius=7, color=(a,b,c), thickness=-1)\n",
        "\n",
        "\n",
        "    combined_image = cv.hconcat([image1_with_points, image2_with_points])\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(cv.cvtColor(combined_image, cv.COLOR_BGR2RGB))\n",
        "    plt.title('ORB Feature Detection: Marked Keypoints')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sUEn0RXCsiB"
      },
      "source": [
        "### Applying Gaussian Blur for Noise Reduction\n",
        "Write a function that applies a Gaussian blur to an image to reduce noise and displays both the original and blurred images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "3_lKp3bICzdl"
      },
      "outputs": [],
      "source": [
        "def blur(image):\n",
        "    blur = cv.blur(image,(11,11))\n",
        "    display_image = np.hstack((image,blur))\n",
        "\n",
        "    plt.imshow(display_image[:,:,::-1])\n",
        "    plt.axis(False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fidnIKLWCzCx"
      },
      "source": [
        "### Pyramid Transform for Image Scaling\n",
        "Create a function that creates a pyramid of images (both up and down) for a given image and displays the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "ABndA3roC5fV"
      },
      "outputs": [],
      "source": [
        "\n",
        "def display_image_pyramid(image_path, levels=3):\n",
        "\n",
        "    image = cv.imread(image_path)\n",
        "    if image is None:\n",
        "        raise IOError(f\"Error loading image from path: {image_path}\")\n",
        "    \n",
        "    \n",
        "    image_rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "\n",
        "    pyramid_down = [image_rgb]\n",
        "    pyramid_up = [image_rgb]\n",
        "\n",
        "    for i in range(levels):\n",
        "        image_rgb = cv.pyrDown(image_rgb)\n",
        "        pyramid_down.append(image_rgb)\n",
        "\n",
        "    image_rgb = pyramid_down[-1]\n",
        "    for i in range(levels):\n",
        "        image_rgb = cv.pyrUp(image_rgb)\n",
        "        pyramid_up.append(image_rgb)\n",
        "\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    total_images = len(pyramid_down) + len(pyramid_up) - 1\n",
        "    for i, img in enumerate(pyramid_down + pyramid_up[1:], start=1):\n",
        "        plt.subplot(2, total_images // 2 + 1, i)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Level {i - 1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.suptitle(\"Image Pyramid (Down and Up)\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHlKUjccC5La"
      },
      "source": [
        "### Implement Harris Corner Detection in Python\n",
        "Write a Python function using OpenCV that takes an image file as input and applies the Harris Corner Detection algorithm. Your function should display the original image with the detected corners marked. Include parameters to specify the block size, ksize, and free parameter for flexibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "beKkD_y0C7Ke"
      },
      "outputs": [],
      "source": [
        "def edgeDet(image,blockSize,ksize,k):\n",
        "\n",
        "    copy_img = image.copy()\n",
        "    gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY) \n",
        "    \n",
        "    dst = cv.cornerHarris(gray_image, blockSize=blockSize, ksize=ksize, k=k) \n",
        "    \n",
        "    dst = cv.dilate(dst, None) \n",
        "    copy_img[dst > 0.01 * dst.max()] = [0, 255, 0] \n",
        "    \n",
        "    plt.imshow(copy_img[:,:,::-1])\n",
        "    plt.axis(False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46_GNSP5DE-Q"
      },
      "source": [
        "### SIFT Keypoint Detection and Description\n",
        "Create a function that reads an image, converts it to grayscale, and then applies the SIFT algorithm to detect keypoints and compute descriptors. Ensure the detected keypoints are visualized on the original image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "SNml8psQDJcb"
      },
      "outputs": [],
      "source": [
        "def detKeypoints(image):\n",
        "    \n",
        "    gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY) \n",
        "    \n",
        "    sift = cv.SIFT_create() \n",
        "    kp, des = sift.detectAndCompute(gray_image, None) \n",
        "    \n",
        "    kp_image = cv.drawKeypoints(image, kp, None, color=( \n",
        "        0, 255, 0), flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS) \n",
        "    \n",
        "    plt.imshow(kp_image[:,:,::-1])\n",
        "    plt.axis(False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9Aa7newDJxY"
      },
      "source": [
        "### Feature Matching using ORB\n",
        "Develop a Python script that matches features between two images using the ORB algorithm. The script should display the matched features between the two images with lines connecting corresponding keypoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "pSFtPxbWDRFz"
      },
      "outputs": [],
      "source": [
        "def matchFet(path1,path2):\n",
        "    image1 = cv.imread(path1, cv.IMREAD_GRAYSCALE)\n",
        "    image2 = cv.imread(path2, cv.IMREAD_GRAYSCALE)\n",
        "\n",
        "    orb = cv.ORB_create()\n",
        "\n",
        "    keypoints1, descriptors1 = orb.detectAndCompute(image1, None)\n",
        "    keypoints2, descriptors2 = orb.detectAndCompute(image2, None)\n",
        "    \n",
        "    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
        "\n",
        "    matches = bf.match(descriptors1, descriptors2)\n",
        "\n",
        "    matches = sorted(matches, key=lambda x: x.distance)\n",
        "\n",
        "    matched_image = cv.drawMatches(image1, keypoints1, image2, keypoints2, matches[:20], None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
        "\n",
        "    matched_image_rgb = cv.cvtColor(matched_image, cv.COLOR_BGR2RGB)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(matched_image_rgb)\n",
        "    plt.title('ORB Feature Matching')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyuM-UuYDRbA"
      },
      "source": [
        "### Implement FAST Corner Detection\n",
        "Write a Python function to implement the FAST corner detection algorithm. The function should accept an image and return the image with detected keypoints highlighted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "4HgLq8f_DTnO"
      },
      "outputs": [],
      "source": [
        "def cornerDet(image):\n",
        "    gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY) \n",
        "  \n",
        "    fast = cv.FastFeatureDetector_create() \n",
        "    fast.setNonmaxSuppression(False) \n",
        "\n",
        "    kp = fast.detect(gray_image, None) \n",
        "    kp_image = cv.drawKeypoints(image, kp, None, color=(0, 255, 0)) \n",
        "    \n",
        "    plt.imshow(kp_image[:,:,::-1]) \n",
        "    plt.axis(False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOJ-25wrDpiC"
      },
      "source": [
        "Tough questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tovusHoWDT6G"
      },
      "source": [
        "### Custom Canny Edge Detector Implementation\n",
        "Implement your own version of the Canny edge detection algorithm from scratch using Python (without using OpenCV functions). Your implementation should include:\n",
        "\n",
        "Gaussian filtering for noise reduction.\n",
        "Calculation of gradient magnitude and direction.\n",
        "Non-maximum suppression.\n",
        "Hysteresis thresholding. Your function should take an image as input and return an image with detected edges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICcFqoUyDr_b"
      },
      "outputs": [],
      "source": [
        "def gaussian_kernel(size, sigma):\n",
        "\n",
        "    k = size // 2\n",
        "    x, y = np.meshgrid(np.arange(-k, k+1), np.arange(-k, k+1))\n",
        "    kernel = (1 / (2 * np.pi * sigma**2)) * np.exp(-(x**2 + y**2) / (2 * sigma**2))\n",
        "    return kernel / kernel.sum()\n",
        "\n",
        "def sobel_filter(image, axis):\n",
        "\n",
        "    if axis == 'x':\n",
        "        kernel = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
        "    elif axis == 'y':\n",
        "        kernel = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
        "    else:\n",
        "        raise ValueError(\"Invalid axis: choose 'x' or 'y'\")\n",
        "    return cv.filter2D(image, -1, kernel)\n",
        "\n",
        "def custom_canny(image, low_threshold, high_threshold, sigma=1.0):\n",
        "\n",
        "    kernel_size = int(6 * sigma + 1) | 1\n",
        "    smoothed = cv.filter2D(image, -1, gaussian_kernel(kernel_size, sigma))\n",
        "\n",
        "    Gx = sobel_filter(smoothed, 'x')\n",
        "    Gy = sobel_filter(smoothed, 'y')\n",
        "    magnitude = np.hypot(Gx, Gy) \n",
        "    direction = np.arctan2(Gy, Gx) \n",
        "\n",
        "    magnitude = (magnitude / magnitude.max()) * 255\n",
        "\n",
        "    suppressed = np.zeros_like(magnitude)\n",
        "    angle = np.rad2deg(direction) % 180 \n",
        "\n",
        "    for x in range(1, image.shape[0] - 1):\n",
        "        for y in range(1, image.shape[1] - 1):\n",
        "            q, r = 255, 255\n",
        "        \n",
        "            if (0 <= angle[x, y] < 22.5) or (157.5 <= angle[x, y] <= 180):\n",
        "                q = magnitude[x, y + 1]\n",
        "                r = magnitude[x, y - 1]\n",
        "            elif 22.5 <= angle[x, y] < 67.5:\n",
        "                q = magnitude[x + 1, y - 1]\n",
        "                r = magnitude[x - 1, y + 1]\n",
        "            elif 67.5 <= angle[x, y] < 112.5:\n",
        "                q = magnitude[x + 1, y]\n",
        "                r = magnitude[x - 1, y]\n",
        "            elif 112.5 <= angle[x, y] < 157.5:\n",
        "                q = magnitude[x - 1, y - 1]\n",
        "                r = magnitude[x + 1, y + 1]\n",
        "\n",
        "            if magnitude[x, y] >= q and magnitude[x, y] >= r:\n",
        "                suppressed[x, y] = magnitude[x, y]\n",
        "            else:\n",
        "                suppressed[x, y] = 0\n",
        "\n",
        "    strong = (suppressed > high_threshold).astype(np.uint8)\n",
        "    weak = ((suppressed >= low_threshold) & (suppressed <= high_threshold)).astype(np.uint8)\n",
        "\n",
        "    edges = np.zeros_like(image)\n",
        "    for x in range(1, image.shape[0] - 1):\n",
        "        for y in range(1, image.shape[1] - 1):\n",
        "            if weak[x, y]:\n",
        "                if (strong[x - 1:x + 2, y - 1:y + 2].any()):\n",
        "                    edges[x, y] = 255\n",
        "            elif strong[x, y]:\n",
        "                edges[x, y] = 255\n",
        "\n",
        "    return edges\n",
        "\n",
        "image = cv.imread('image.jpg', cv.IMREAD_GRAYSCALE)\n",
        "edges = cv.cvtColor(custom_canny(image, low_threshold=50, high_threshold=100, sigma=1.0),cv.COLOR_GRAY2RGB)\n",
        "\n",
        "plt.imshow(edges[:,::-1])\n",
        "plt.axis(False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIkqyboUDsWO"
      },
      "source": [
        "### Multi-Scale Feature Detection\n",
        "Create a function that applies multi-scale feature detection using the Laplacian of Gaussian (LoG) method. This function should take an image and a list of sigma values as input, and return an image or set of images showing detected features at the different scales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZ3prYBsDwPy"
      },
      "outputs": [],
      "source": [
        "def laplacian_of_gaussian(image, sigmas):\n",
        "    \n",
        "    if len(image.shape) == 3:\n",
        "        image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "    image = image / 255.0\n",
        "\n",
        "    log_images = []\n",
        "    feature_images = []\n",
        "\n",
        "    for sigma in sigmas:\n",
        "        \n",
        "        ksize = int(6 * sigma + 1)\n",
        "        if ksize % 2 == 0:\n",
        "            ksize += 1 \n",
        "\n",
        "        blurred = cv.GaussianBlur(image, (ksize, ksize), sigma)\n",
        "\n",
        "        log = cv.Laplacian(blurred, cv.CV_64F, ksize=ksize)\n",
        "\n",
        "        zero_crossings = np.zeros_like(log, dtype=np.uint8)\n",
        "        rows, cols = log.shape\n",
        "        for i in range(1, rows - 1):\n",
        "            for j in range(1, cols - 1):\n",
        "                patch = log[i-1:i+2, j-1:j+2]\n",
        "                if (patch.max() > 0 and patch.min() < 0):\n",
        "                    zero_crossings[i, j] = 255\n",
        "\n",
        "        log_images.append(log)\n",
        "        feature_images.append(zero_crossings)\n",
        "\n",
        "    return feature_images, log_images\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    image = cv.imread(\"image.jpg\", cv.IMREAD_GRAYSCALE)\n",
        "\n",
        "    sigma_values = [1, 2, 3, 4]\n",
        "\n",
        "    feature_images, log_images = laplacian_of_gaussian(image, sigma_values)\n",
        "\n",
        "    for idx, (features, log_img) in enumerate(zip(feature_images, log_images)):\n",
        "        cv.imshow(f\"LoG Features (sigma={sigma_values[idx]})\", features)\n",
        "        cv.imshow(f\"LoG Raw (sigma={sigma_values[idx]})\", cv.convertScaleAbs(log_img))\n",
        "    \n",
        "    cv.waitKey(0)\n",
        "    cv.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCpFBjRSD8yh"
      },
      "source": [
        "## Bonus Question\n",
        "\n",
        "Do your Research on how can we make a 3d model from the Refined frames.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVr5vt5FEQSr"
      },
      "outputs": [],
      "source": [
        "### Write your answer here."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
