{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93XQHTufB3_O"
      },
      "source": [
        "### Implement Edge Detection\n",
        "\n",
        "Write a Python function using OpenCV that takes an image file path as input,applies Canny edge detection on the image,and displays the original and edge-detected images side by side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVSmMDmk_s1R"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt \n",
        "def canny_edge(path):\n",
        "    img=cv2.imread(path)\n",
        "    edges=cv2.Canny(img,100,160)\n",
        "    plt.subplot(121);plt.imshow(img[:,:,::-1]);plt.title(\"Original Image\");plt.axis(\"off\")\n",
        "    plt.subplot(122);plt.imshow(edges,cmap='Greys_r');plt.title(\"Edge-Detected Image\");plt.axis(\"off\")\n",
        "canny_edge('image.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRzoOxEvCPyl"
      },
      "source": [
        "### Face and Eye Detection\n",
        "\n",
        "Create a function that detects faces and eyes in a given image using Haar cascades in OpenCV. The function should draw rectangles around detected faces and eyes and display the output image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4irktxYCQKJ"
      },
      "outputs": [],
      "source": [
        "def face_eye_detection(img):\n",
        "    import requests\n",
        "    face_url=\"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\" \n",
        "    eye_url=\"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_eye.xml\" \n",
        "    face_filename=\"haarcascade_frontalface_default.xml\" \n",
        "    eye_filename=\"haarcascade_eye.xml\"\n",
        "    response=requests.get(face_url) \n",
        "    with open(face_filename,'wb') as file: \n",
        "        file.write(response.content)\n",
        "    face_cascade=cv2.CascadeClassifier(face_filename)\n",
        "    response=requests.get(eye_url)\n",
        "    with open(eye_filename,'wb') as file:\n",
        "        file.write(response.content)\n",
        "    eye_cascade=cv2.CascadeClassifier(eye_filename)\n",
        "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "    faces=face_cascade.detectMultiScale(gray,1.3,5)\n",
        "    for (x,y,w,h) in faces:\n",
        "        face_img=cv2.rectangle(img.copy(),(x,y),(x+w,y+h),(0,255,0),2)\n",
        "        roi_gray=gray[y:y+h,x:x+w]\n",
        "        roi_color=face_img[y:y+h,x:x+w]\n",
        "        eyes=eye_cascade.detectMultiScale(roi_gray)\n",
        "        for (ex,ey,ew,eh) in eyes:\n",
        "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,0,0),2)\n",
        "    plt.figure()\n",
        "    plt.imshow(cv2.cvtColor(face_img,cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "img=cv2.imread('image.jpg')\n",
        "face_eye_detection(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h59b-BnvCbWe"
      },
      "source": [
        "###Image Cropping Based on Facial Features\n",
        "\n",
        "Write a function that takes an image path as input and detects faces. If exactly one face is detected,return the cropped image of the face. Use Haar cascades for face detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sukHNd-sCbHe"
      },
      "outputs": [],
      "source": [
        "def detect(img_path):\n",
        "    import requests\n",
        "    img=cv2.imread(img_path)\n",
        "    face_url=\"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\" \n",
        "    eye_url=\"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_eye.xml\" \n",
        "    face_filename=\"haarcascade_frontalface_default.xml\" \n",
        "    eye_filename=\"haarcascade_eye.xml\"\n",
        "    response=requests.get(face_url) \n",
        "    with open(face_filename,'wb') as file: \n",
        "        file.write(response.content)\n",
        "    face_cascade=cv2.CascadeClassifier(face_filename)\n",
        "    response=requests.get(eye_url)\n",
        "    with open(eye_filename,'wb') as file:\n",
        "        file.write(response.content)\n",
        "    eye_cascade=cv2.CascadeClassifier(eye_filename)\n",
        "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "    faces=face_cascade.detectMultiScale(gray,1.3,5)\n",
        "    for (x,y,w,h) in faces:\n",
        "        face_img=cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
        "        roi_gray=gray[y:y+h,x:x+w]\n",
        "        roi_color=face_img[y:y+h,x:x+w]\n",
        "    if len(faces)==1:\n",
        "        plt.imshow(cv2.cvtColor(roi_color,cv2.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print('No face detected or more than one faces detected')\n",
        "detect('image.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zeYFj9nCnqX"
      },
      "source": [
        "### Feature Matching with ORB\n",
        "Create a Python script that uses ORB to detect and match features between two images. The script should display the matched keypoints on the output image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpczpHxCCr74"
      },
      "outputs": [],
      "source": [
        "image1=cv2.imread('image1.jpg')\n",
        "image2=cv2.imread('image2.jpg')\n",
        "gray_img1=cv2.cvtColor(image1,cv2.COLOR_BGR2GRAY)\n",
        "gray_img2=cv2.cvtColor(image2,cv2.COLOR_BGR2GRAY)\n",
        "orb=cv2.ORB_create(nfeatures=2000)\n",
        "kp1,des1=orb.detectAndCompute(gray_img1,None) \n",
        "kp2,des2=orb.detectAndCompute(gray_img2,None)\n",
        "bf=cv2.BFMatcher()\n",
        "matches=bf.match(des1,des2)\n",
        "matched_image=cv2.drawMatches(image1,kp1,image2,kp2,matches[:],None)\n",
        "plt.imshow(matched_image)\n",
        "plt.title('Feature Matching with ORB')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sUEn0RXCsiB"
      },
      "source": [
        "### Applying Gaussian Blur for Noise Reduction\n",
        "Write a function that applies a Gaussian blur to an image to reduce noise and displays both the original and blurred images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_lKp3bICzdl"
      },
      "outputs": [],
      "source": [
        "def gaussian_blur(img):\n",
        "    blurred_image=cv2.GaussianBlur(img,(5,5),0)\n",
        "    plt.subplot(121);plt.imshow(img[:,:,::-1]);plt.title(\"Original Image\");plt.axis(\"off\")\n",
        "    plt.subplot(122);plt.imshow(blurred_image[:,:,::-1]);plt.title(\"Blurred Image\");plt.axis(\"off\")\n",
        "    plt.axis('off')\n",
        "gaussian_blur(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fidnIKLWCzCx"
      },
      "source": [
        "### Pyramid Transform for Image Scaling\n",
        "Create a function that creates a pyramid of images (both up and down) for a given image and displays the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pyramid(img,layers):\n",
        "    cv2.imshow(\"Original\",img)\n",
        "    down_pyramid=[]\n",
        "    temp=img\n",
        "    for i in range(layers):\n",
        "        temp=cv2.pyrDown(temp)\n",
        "        down_pyramid.append(temp)\n",
        "        cv2.imshow(f\"Down Pyramid {i+1}\",temp)\n",
        "    up_pyramid=[]\n",
        "    temp=down_pyramid[-1]\n",
        "    for i in range(layers):\n",
        "        temp=cv2.pyrUp(temp)\n",
        "        up_pyramid.append(temp)\n",
        "        cv2.imshow(f\"Up Pyramid {i+1}\",temp)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "pyramid(img,3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHlKUjccC5La"
      },
      "source": [
        "### Implement Harris Corner Detection in Python\n",
        "Write a Python function using OpenCV that takes an image file as input and applies the Harris Corner Detection algorithm. Your function should display the original image with the detected corners marked. Include parameters to specify the block size,ksize,and free parameter for flexibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beKkD_y0C7Ke"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def harris_corner(img,blocksize,ksize,k):\n",
        "    gray_image=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) \n",
        "    gray_image=np.float32(gray_image) \n",
        "    dst=cv2.cornerHarris(gray_image,blockSize=blocksize,ksize=ksize,k=k) \n",
        "    dst=cv2.dilate(dst,None) \n",
        "    img[dst > 0.01 * dst.max()]=[0,255,0] \n",
        "    plt.imshow(img[:,:,::-1]) \n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "harris_corner(img.copy(),2,3,0.04)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46_GNSP5DE-Q"
      },
      "source": [
        "### SIFT Keypoint Detection and Description\n",
        "Create a function that reads an image,converts it to grayscale,and then applies the SIFT algorithm to detect keypoints and compute descriptors. Ensure the detected keypoints are visualized on the original image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNml8psQDJcb"
      },
      "outputs": [],
      "source": [
        "def sift_keypoint_detection(path):\n",
        "    image=cv2.imread(path)\n",
        "    gray_img=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "    sift=cv2.SIFT_create()\n",
        "    kp,des=sift.detectAndCompute(gray_img,None)\n",
        "    img_with_keypoints=cv2.drawKeypoints(image,kp,None)\n",
        "    img_with_keypoints_rgb=cv2.cvtColor(img_with_keypoints,cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(img_with_keypoints_rgb)\n",
        "    plt.title('SIFT Keypoint Detection')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "sift_keypoint_detection('image.jpg')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9Aa7newDJxY"
      },
      "source": [
        "### Feature Matching using ORB\n",
        "Develop a Python script that matches features between two images using the ORB algorithm. The script should display the matched features between the two images with lines connecting corresponding keypoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSFtPxbWDRFz"
      },
      "outputs": [],
      "source": [
        "image1=cv2.imread('image1.jpg')\n",
        "image2=cv2.imread('image2.jpg')\n",
        "gray_img1=cv2.cvtColor(image1,cv2.COLOR_BGR2GRAY)\n",
        "gray_img2=cv2.cvtColor(image2,cv2.COLOR_BGR2GRAY)\n",
        "orb=cv2.ORB_create(nfeatures=2000)\n",
        "kp1,des1=orb.detectAndCompute(gray_img1,None) \n",
        "kp2,des2=orb.detectAndCompute(gray_img2,None)\n",
        "bf=cv2.BFMatcher()\n",
        "matches=bf.match(des1,des2)\n",
        "matched_image=cv2.drawMatches(image1,kp1,image2,kp2,matches[:],None)\n",
        "plt.imshow(matched_image)\n",
        "plt.title('Feature Matching with ORB')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyuM-UuYDRbA"
      },
      "source": [
        "### Implement FAST Corner Detection\n",
        "Write a Python function to implement the FAST corner detection algorithm. The function should accept an image and return the image with detected keypoints highlighted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HgLq8f_DTnO"
      },
      "outputs": [],
      "source": [
        "def fast_corner_detection(image):\n",
        "    gray_image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "    fast=cv2.FastFeatureDetector_create()\n",
        "    kp=fast.detect(gray_image,None)\n",
        "    image_with_kp=cv2.drawKeypoints(image,kp,None,color=(0,255,0))\n",
        "    image_with_kp_rgb=cv2.cvtColor(image_with_kp,cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(image_with_kp_rgb)\n",
        "    plt.title('FAST Corner Detection')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "fast_corner_detection(img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOJ-25wrDpiC"
      },
      "source": [
        "Tough questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tovusHoWDT6G"
      },
      "source": [
        "### Custom Canny Edge Detector Implementation\n",
        "Implement your own version of the Canny edge detection algorithm from scratch using Python (without using OpenCV functions). Your implementation should include:\n",
        "\n",
        "Gaussian filtering for noise reduction.\n",
        "Calculation of gradient magnitude and direction.\n",
        "Non-maximum suppression.\n",
        "Hysteresis thresholding. Your function should take an image as input and return an image with detected edges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICcFqoUyDr_b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def custom_canny(image_path, low_threshold=0.05, high_threshold=0.15):\n",
        "    def gaussian_kernel(size, sigma=1.0):\n",
        "        k=cv2.getGaussianKernel(size, sigma)\n",
        "        kernel=k*k.T\n",
        "        return kernel\n",
        "    def apply_filter(image, kernel):\n",
        "        return cv2.filter2D(image, -1, kernel)\n",
        "    def gradient_magnitude_and_direction(image):\n",
        "        Kx=np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
        "        Ky=np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n",
        "        Ix=apply_filter(image, Kx)\n",
        "        Iy=apply_filter(image, Ky)\n",
        "        magnitude=np.sqrt(Ix**2 + Iy**2)\n",
        "        direction=np.arctan2(Iy, Ix)\n",
        "        return magnitude, direction\n",
        "\n",
        "    def non_maximum_suppression(magnitude, direction):\n",
        "        M, N=magnitude.shape\n",
        "        Z=np.zeros((M, N), dtype=np.int32)\n",
        "        angle=direction * 180. / np.pi\n",
        "        angle[angle < 0] += 180\n",
        "        for i in range(1, M-1):\n",
        "            for j in range(1, N-1):\n",
        "                try:\n",
        "                    q=255\n",
        "                    r=255\n",
        "                    if (0 <= angle[i, j] < 22.5) or (157.5 <= angle[i, j] <= 180):\n",
        "                        q=magnitude[i, j+1]\n",
        "                        r=magnitude[i, j-1]\n",
        "                    elif (22.5 <= angle[i, j] < 67.5):\n",
        "                        q=magnitude[i+1, j-1]\n",
        "                        r=magnitude[i-1, j+1]\n",
        "                    elif (67.5 <= angle[i, j] < 112.5):\n",
        "                        q=magnitude[i+1, j]\n",
        "                        r=magnitude[i-1, j]\n",
        "                    elif (112.5 <= angle[i, j] < 157.5):\n",
        "                        q=magnitude[i-1, j-1]\n",
        "                        r=magnitude[i+1, j+1]\n",
        "                    if (magnitude[i, j] >= q) and (magnitude[i, j] >= r):\n",
        "                        Z[i, j]=magnitude[i, j]\n",
        "                    else:\n",
        "                        Z[i, j]=0\n",
        "                except IndexError as e:\n",
        "                    pass\n",
        "        return Z\n",
        "\n",
        "    def threshold(image, low, high):\n",
        "        highThreshold=image.max() * high\n",
        "        lowThreshold=highThreshold * low\n",
        "        M, N=image.shape\n",
        "        res=np.zeros((M, N), dtype=np.int32)\n",
        "        strong=np.int32(255)\n",
        "        weak=np.int32(75)\n",
        "        strong_i, strong_j=np.where(image >= highThreshold)\n",
        "        zeros_i, zeros_j=np.where(image < lowThreshold)\n",
        "        weak_i, weak_j=np.where((image <= highThreshold) & (image >= lowThreshold))\n",
        "        res[strong_i, strong_j]=strong\n",
        "        res[weak_i, weak_j]=weak\n",
        "        return res, weak, strong\n",
        "    def hysteresis(image, weak, strong=255):\n",
        "        M, N=image.shape\n",
        "        for i in range(1, M-1):\n",
        "            for j in range(1, N-1):\n",
        "                if (image[i, j]==weak):\n",
        "                    try:\n",
        "                        if ((image[i+1, j-1]==strong) or (image[i+1, j]==strong) or (image[i+1, j+1]==strong)\n",
        "                            or (image[i, j-1]==strong) or (image[i, j+1]==strong)\n",
        "                            or (image[i-1, j-1]==strong) or (image[i-1, j]==strong) or (image[i-1, j+1]==strong)):\n",
        "                            image[i, j]=strong\n",
        "                        else:\n",
        "                            image[i, j]=0\n",
        "                    except IndexError as e:\n",
        "                        pass\n",
        "        return image\n",
        "\n",
        "    image=cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    kernel=gaussian_kernel(size=5, sigma=1.4)\n",
        "    smoothed_image=apply_filter(image, kernel)\n",
        "    magnitude, direction=gradient_magnitude_and_direction(smoothed_image)\n",
        "    non_max_image=non_maximum_suppression(magnitude, direction)\n",
        "    threshold_image, weak, strong=threshold(non_max_image, low_threshold, high_threshold)\n",
        "    final_image=hysteresis(threshold_image, weak, strong)\n",
        "    return final_image\n",
        "edges = custom_canny('image.jpg')\n",
        "plt.imshow(edges, cmap='gray')\n",
        "plt.title('Custom Canny Edge Detection')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIkqyboUDsWO"
      },
      "source": [
        "### Multi-Scale Feature Detection\n",
        "Create a function that applies multi-scale feature detection using the Laplacian of Gaussian (LoG) method. This function should take an image and a list of sigma values as input,and return an image or set of images showing detected features at the different scales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def multi_scale_feature_detection(image_path,sigma_values):\n",
        "    image=cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
        "    if len(image.shape)==3:\n",
        "        image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "    results=[]\n",
        "    for sigma in sigma_values:\n",
        "        blurred=cv2.GaussianBlur(image,(0,0),sigmaX=sigma,sigmaY=sigma)\n",
        "        log_image=cv2.Laplacian(blurred,cv2.CV_64F)\n",
        "        log_image_normalized=(log_image - log_image.min())/(log_image.max() - log_image.min())\n",
        "        results.append((sigma,log_image_normalized))\n",
        "    for i in range(len(sigma_values)):\n",
        "        sigma,feature_map=results[i]\n",
        "        plt.subplot(1,len(sigma_values),i + 1)\n",
        "        plt.imshow(feature_map,cmap='gray')\n",
        "        plt.title(f\"Sigma: {sigma}\")\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "multi_scale_feature_detection(\"image.jpg\",[1.0,2.0,4.0,8.0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCpFBjRSD8yh"
      },
      "source": [
        "## Bonus Question\n",
        "\n",
        "Do your Research on how can we make a 3d model from the Refined frames.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
